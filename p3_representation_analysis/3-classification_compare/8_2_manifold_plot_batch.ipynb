{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.collections import LineCollection\n",
    "import os\n",
    "from utils.color_map import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20230417-fly2', '20230420-fly2', '20230420-fly3', '20230428-fly1', '20230507-fly1', '20230510-fly1', '20230510-fly2', '20230511-fly2', '20230511-fly3', '20230515-fly1', 'DEEPCAD', 'figures', 'figures-for-ver16-final6']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "result_path = os.path.abspath('../results/Ach-ver16')\n",
    "folder_name = 'voxel-integration-region-SRD-long-formal'\n",
    "num_dim_file = 'list_list_num_dim.npy'\n",
    "fly_selected = [0,1,2,3,4,5,6,7,8,9]\n",
    "# parameters \n",
    "if_shuffle = False\n",
    "thresh = np.arange(0,1,0.02)\n",
    "channel = np.array([0,1,2])\n",
    "num_channel_choice = len(channel)\n",
    "dim_thresh = 25\n",
    "if_save =  False\n",
    "if if_save:\n",
    "    figure_save_path = result_path + '/' + 'figures-for-ver16-final6'+'/manifold-SRD-long-formal--3-40'\n",
    "    f = os.path.exists(figure_save_path)\n",
    "    if not f:\n",
    "        os.makedirs(figure_save_path)\n",
    "cv_fold = 5\n",
    "kf = KFold(n_splits=cv_fold,shuffle = True,random_state = 5)\n",
    "time_range = range(0,43)# time range\n",
    "\n",
    "# load data\n",
    "file_folders = os.listdir(result_path)\n",
    "print(file_folders)\n",
    "num_fly = len(fly_selected)\n",
    "yy = np.zeros((num_fly,num_channel_choice))\n",
    "for i in range(num_fly):\n",
    "    file_folder = file_folders[fly_selected[i]]\n",
    "    the_path = result_path + '/' + file_folder + '/' + folder_name\n",
    "    f = os.path.exists(the_path + '/' + num_dim_file)\n",
    "    if not f:\n",
    "        continue\n",
    "    num_dim = np.load(the_path + '/' + num_dim_file)\n",
    "    num_dim = np.squeeze(num_dim)\n",
    "    if not if_shuffle:\n",
    "        num_dim = num_dim[:,:,0]\n",
    "    for j in range(num_channel_choice):\n",
    "        a = np.where(np.squeeze(num_dim[j,:])>=dim_thresh)\n",
    "        a = np.array(a[0])\n",
    "        yy[i,j] = thresh[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "['block_dim_c0.npy', 'channel_0_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_1_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'channel_2_response_thresh_0.7_pca_thresh_0.9_block_size_0.1_odor_choice_0_downsample', 'list_list_accuracy.npy', 'list_list_accuracy_svm.npy', 'list_list_AUC_weighted.npy', 'list_list_f1_weighted.npy', 'list_list_num_dim.npy', 'list_list_stim.npy', 'p1-classification-pca-whole-brain-integration_region_lda_tp_pca_only_stim.ipynb', 'pca_data_c0.npy']\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(num_fly):\n",
    "    file_folder = file_folders[fly_selected[ii]]\n",
    "    the_path = result_path + '/' + file_folder + '/' + folder_name\n",
    "    the_sub_path = os.listdir(the_path)\n",
    "    print(the_sub_path)\n",
    "    j_flag = 0\n",
    "    for j in range(len(the_sub_path)):\n",
    "        if 'channel' not in the_sub_path[j]:\n",
    "            continue\n",
    "        the_sub_path_full = the_path + '/' + the_sub_path[j] + '/' + 'No_Shuffle'\n",
    "        sub_data_path = os.listdir(the_sub_path_full)\n",
    "        for m in range(len(sub_data_path)):\n",
    "            if str(yy[ii,j_flag])+'_' in sub_data_path[m] and '.npy' in sub_data_path[m] :\n",
    "                the_final_path = the_sub_path_full + '/' + sub_data_path[m]\n",
    "                data = np.load(the_final_path)\n",
    "                stim_file_name = 'stim.npy'\n",
    "                stim = np.load(the_sub_path_full + '/' + stim_file_name)\n",
    "                print(np.shape(stim))\n",
    "                num_trial = len(stim)\n",
    "                list_train = []\n",
    "                list_test = []\n",
    "                for train, test in kf.split(np.linspace(0,num_trial-1,num_trial)):\n",
    "                    list_train.append(train)\n",
    "                    list_test.append(test)\n",
    "                list_train = np.array(list_train)\n",
    "                list_test = np.array(list_test)\n",
    "                filename = sub_data_path[m]\n",
    "                if data.ndim==2:\n",
    "                    stim_flag = stim\n",
    "                    data = data.reshape((int(np.size(data,0)/num_trial),num_trial,-1),order = 'F')\n",
    "                    data = data[:,:,[0,1]]###\n",
    "                    trial_flag = range(180)\n",
    "                    num_tp = len(time_range)\n",
    "                else:\n",
    "                    number = int(filename[-5:-4])-1\n",
    "                    flag = filename[0:4]\n",
    "                    if flag == 'test':\n",
    "                        stim_flag = stim[list_test[number,:]]\n",
    "                        trial_flag = list_test[number,:]\n",
    "                    else:\n",
    "                        stim_flag = stim[list_train[number,:]]\n",
    "                        trial_flag = list_train[number,:]\n",
    "                    num_tp = len(time_range)\n",
    "                #################################\n",
    "                # plot-1 color-stim \n",
    "                color_list = ['royalblue','firebrick','darkorange']\n",
    "                label = ['OCT','MCH','EA']\n",
    "                plt.figure(figsize=(3,3))\n",
    "                ax = plt.axes()\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                cnt = [0,0,0]\n",
    "                ############\n",
    "                # rearrange\n",
    "                start = (np.squeeze(data[0,:,:])).copy()\n",
    "                start = np.mean(start,0)\n",
    "                for i in range(np.size(data,0)):\n",
    "                    data[i,:,:] = data[i,:,:]-start\n",
    "                a = data[5:13,stim_flag==1,:]\n",
    "                a = np.mean(np.mean(a,0),0)\n",
    "                b = data[5:13,stim_flag==2,:]\n",
    "                b = np.mean(np.mean(b,0),0)\n",
    "                c = data[5:13,stim_flag==3,:]\n",
    "                c = np.mean(np.mean(c,0),0)\n",
    "                if a[1]<b[1]:# OCT MCH opposite\n",
    "                    data[:,:,1] = 0-data[:,:,1]\n",
    "                if c[0]<b[0]:# EA MCH \n",
    "                    data[:,:,0] = 0-data[:,:,0]\n",
    "                ####################\n",
    "                for i in range(np.size(data,1)):\n",
    "                    plt.plot(data[time_range,i,0],data[time_range,i,1],c = color_list[stim_flag[i]-1],label = label[stim_flag[i]-1],linewidth=1.5)\n",
    "                    cnt[stim_flag[i]-1] = cnt[stim_flag[i]-1]+1\n",
    "                    if cnt[0]==1 and cnt[1]==1 and cnt[2]==1:\n",
    "                        plt.legend(loc = 4)\n",
    "                # ax.set_xlim(np.min(data[:,:,0])-0.1*abs(np.min(data[:,:,0])), np.max(data[:,:,0])+0.1*abs(np.max(data[:,:,0])))\n",
    "                # ax.set_ylim(np.min(data[:,:,1])-0.1*abs(np.min(data[:,:,1])), np.max(data[:,:,1])+0.1*abs(np.max(data[:,:,1])))\n",
    "                ax.set_xlim(-11,10)\n",
    "                ax.set_ylim(-10,10)\n",
    "                if if_save:\n",
    "                    mpl.rcParams['pdf.fonttype'] = 42\n",
    "                    mpl.rcParams['ps.fonttype'] = 42\n",
    "                    the_save_path = figure_save_path +'/'+file_folder +'_No_shuffle'\n",
    "                    f = os.path.exists(the_save_path)\n",
    "                    if not f:\n",
    "                        os.makedirs(the_save_path)\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename +'_stim.pdf',dpi = 300,bbox_inches = 'tight')\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename +'_stim.png',dpi = 300,bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "                ######################################\n",
    "                # plot-2 color-trial\n",
    "                color_list = plt.cm.coolwarm(np.linspace(0,1,num_trial))\n",
    "\n",
    "                fig = plt.figure(figsize=(3,3))\n",
    "                ax = plt.axes()\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                m = plt.subplot(1,1,1)\n",
    "                cnt = [0,0,0]\n",
    "                for i in range(np.size(data,1)):\n",
    "                    plt.plot(data[time_range,i,0],data[time_range,i,1],c = color_list[trial_flag[i]],linewidth=1.5)\n",
    "                # m.set_xlim(np.min(data[:,:,0])-0.1*abs(np.min(data[:,:,0])), np.max(data[:,:,0])+0.1*abs(np.max(data[:,:,0])))\n",
    "                # m.set_ylim(np.min(data[:,:,1])-0.1*abs(np.min(data[:,:,1])), np.max(data[:,:,1])+0.1*abs(np.max(data[:,:,1])))\n",
    "                ax.set_xlim(-11,10)\n",
    "                ax.set_ylim(-10,10)\n",
    "                fig.subplots_adjust(bottom=0.108)\n",
    "\n",
    "                #colorbar\n",
    "                l = 0.7\n",
    "                b = 0\n",
    "                w = 0.2\n",
    "                h = 0.02 \n",
    "                rect = [l,b,w,h] \n",
    "                cbar_ax = fig.add_axes(rect) \n",
    "                cmap1 = copy.copy(mpl.cm.coolwarm)\n",
    "                norm1 = mpl.colors.Normalize(vmin=1, vmax=num_trial)\n",
    "                im1 = mpl.cm.ScalarMappable(norm=norm1, cmap=cmap1)\n",
    "                cbar1 = plt.colorbar(\n",
    "                    im1, orientation='horizontal',\n",
    "                    ticks=np.linspace(1, num_trial, 2),\n",
    "                    label='Trials',cax=cbar_ax)\n",
    "                if if_save:\n",
    "                    mpl.rcParams['pdf.fonttype'] = 42\n",
    "                    mpl.rcParams['ps.fonttype'] = 42\n",
    "                    the_save_path = figure_save_path +'/'+file_folder +'_No_shuffle'\n",
    "                    f = os.path.exists(the_save_path)\n",
    "                    if not f:\n",
    "                        os.makedirs(the_save_path)\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename +'_trial.png',dpi = 300,bbox_inches = 'tight')\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename +'_trial.pdf',dpi = 300,bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "                ########################################\n",
    "                # plot-3 color-tp\n",
    "                flag = 0\n",
    "                for train, test in kf.split(np.linspace(0,num_trial-1,num_trial)):\n",
    "                    if flag ==int(filename[-5])-1:\n",
    "                        if filename[0:4]=='trai':\n",
    "                            stim_train = train\n",
    "                        else:\n",
    "                            stim_train = test\n",
    "                        break\n",
    "                    flag=flag+1\n",
    "                fig = plt.figure(figsize=(3,3))\n",
    "                ax = plt.axes()\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                m = plt.subplot(1,1,1)\n",
    "                data = data[time_range,:,:]\n",
    "                data_mean = np.zeros((np.size(data,0),3,np.size(data,2)))\n",
    "                for i in range(3):\n",
    "                    data_mean[:,i,:] = np.mean(data[:,stim[stim_train]==i+1,:],1)\n",
    "                    x1 = np.linspace(0,1,num_tp)\n",
    "                    y1 = data_mean[:,i,0]\n",
    "                    x2 = np.linspace(0,1,num_tp)\n",
    "                    y2 = data_mean[:,i,1]\n",
    "                    ps = np.stack((y1,y2), axis=1)\n",
    "                    segments = np.stack((ps[:-1], ps[1:]), axis=1)\n",
    "\n",
    "                    cmap = 'coolwarm'\n",
    "                    colors = color_map(x1[:-1], cmap)\n",
    "                    line_segments = LineCollection(segments, colors=colors, linewidths=1.5, linestyles='solid', cmap=cmap)\n",
    "                    m.add_collection(line_segments)\n",
    "                # m.set_xlim(np.min(data_mean[:,:,0])-0.1*abs(np.min(data_mean[:,:,0])), np.max(data_mean[:,:,0])+0.1*abs(np.max(data_mean[:,:,0])))\n",
    "                # m.set_ylim(np.min(data_mean[:,:,1])-0.1*abs(np.min(data_mean[:,:,1])), np.max(data_mean[:,:,1])+0.1*abs(np.max(data_mean[:,:,1])))\n",
    "                m.set_xlim(-11,10)\n",
    "                m.set_ylim(-10,10)\n",
    "                fig.subplots_adjust(bottom=0.108)\n",
    "\n",
    "                #colorbar\n",
    "                l = 0.7\n",
    "                b = 0\n",
    "                w = 0.2\n",
    "                h = 0.02 \n",
    "                rect = [l,b,w,h] \n",
    "                cbar_ax = fig.add_axes(rect) \n",
    "                cmap1 = copy.copy(mpl.cm.coolwarm)\n",
    "                norm1 = mpl.colors.Normalize(vmin=0, vmax=int(19/30*13))\n",
    "                im1 = mpl.cm.ScalarMappable(norm=norm1, cmap=cmap1)\n",
    "                cbar1 = plt.colorbar(\n",
    "                    im1, orientation='horizontal',\n",
    "                    ticks=np.linspace(0, int(19/30*13), 2),\n",
    "                    label='Time After Odor Delivery (s)',cax=cbar_ax)\n",
    "                if if_save:\n",
    "                    mpl.rcParams['pdf.fonttype'] = 42\n",
    "                    mpl.rcParams['ps.fonttype'] = 42\n",
    "                    the_save_path = figure_save_path +'/'+file_folder +'_No_shuffle'\n",
    "                    f = os.path.exists(the_save_path)\n",
    "                    if not f:\n",
    "                        os.makedirs(the_save_path)\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename+'_tp_mean.png',dpi = 300,bbox_inches = 'tight')\n",
    "                    plt.savefig(the_save_path + '/' +'channel_'+str(j_flag)+'_'+filename +'_tp_mean.pdf',dpi = 300,bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "        j_flag = j_flag+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
