{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.p2_pca_lda import *\n",
    "import tifffile as tf\n",
    "import random\n",
    "# label\n",
    "stim = np.array([3,1,2,3,2,1,3,1,2,1,2,3,1,2,3,2,3,1,3,2,1,2,3,1,2,3,1,2,1,3,2,3,1,2,3,1,3,1,2,3,1,2,3,2,1,2,1,3,2,1,3,1,2,3,1,2,3,2,1,3,1,2,3,2,1,3,1,3,2,3,2,1,3,2,1,3,1,2,3,2,1,3,1,2,3,2,1,2,3,1,\n",
    "                 3,1,2,3,1,2,3,2,1,2,3,1,2,1,3,2,1,3,1,3,2,3,1,2,1,2,3,2,3,1,2,3,1,3,2,1,2,3,1,2,1,3,1,2,3,2,3,1,2,1,3,1,3,2,3,1,2,1,2,3,2,1,3,1,2,3,2,3,1,3,1,2,1,3,2,1,3,2,3,1,2,3,2,1,2,1,3,1,2,3])\n",
    "# brain region\n",
    "br_index = np.array([64,65,66,55,72,73,74,63,23])\n",
    "br_name = np.array(['MBPED_L','MBVL_L','MBML_L','LH_L','SLP_L','SIP_L','SMP_L','CRE_L','EB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ach\n",
    "file_folder_list_1 = ['20230417-nsyb-G7f-rAch1h/fly2/data',\n",
    "                        '20230420-nsyb-G7f-rAch1h/fly2/data',\n",
    "                        '20230420-nsyb-G7f-rAch1h/fly3/data',\n",
    "                        '20230428-nsyb-G7f-rAch1h/fly1/data',\n",
    "                        '20230507-nsyb-G7f-rAch1h/fly1/data',\n",
    "                        '20230510-nsyb-G7f-rAch1h/fly1/data',\n",
    "                        '20230510-nsyb-G7f-rAch1h/fly2/data',\n",
    "                        '20230511-nsyb-G7f-rAch1h/fly2/data',\n",
    "                        '20230511-nsyb-G7f-rAch1h/fly3/data',\n",
    "                        '20230515-nsyb-G7f-rAch1h/fly1/data']\n",
    "file_folder_list_2 = ['20230417-fly2', '20230420-fly2', '20230420-fly3', '20230428-fly1', \n",
    "                 '20230507-fly1', '20230510-fly1', '20230510-fly2', '20230511-fly2', '20230511-fly3', '20230515-fly1']\n",
    "# ## 5HT\n",
    "# file_folder_list_1 = ['20230429-nsyb-G7f-r5HT1.0/fly1/data',\n",
    "#                         '20230506-nsyb-G7f-r5HT1.0/fly1/data',\n",
    "#                         '20230513-nsyb-G7f-r5HT1.0/fly1/data',\n",
    "#                         '20230513-nsyb-G7f-r5HT1.0/fly2/data',\n",
    "#                         '20230516-nsyb-G7f-r5HT1.0/fly2/data',\n",
    "#                         '20230516-nsyb-G7f-r5HT1.0/fly4/data',\n",
    "#                         '20230517-nsyb-G7f-r5HT1.0/fly1/data',\n",
    "#                         '20230601-nsyb-G7f-r5HT1.0/fly1/data',\n",
    "#                         '20230601-nsyb-G7f-r5HT1.0/fly3/data',\n",
    "#                         '20230603-nsyb-G7f-r5HT1.0/fly1/data']\n",
    "# file_folder_list_2 = ['20230429-r5HT1.0-fly1', '20230506-r5HT1.0-fly1', '20230513-r5HT1.0-fly1', '20230513-r5HT1.0-fly2', \n",
    "#                 '20230516-r5HT1.0-fly2', '20230516-r5HT1.0-fly4', '20230517-r5HT1.0-fly1', '20230601-r5HT1.0-fly1', \n",
    "#                 '20230601-r5HT1.0-fly3', '20230603-r5HT1.0-fly1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230420-nsyb-G7f-rAch1h/fly2/data\n"
     ]
    }
   ],
   "source": [
    "## read data\n",
    "data_path = '../../../results/3.odor_random_90_times_OCT_MCH_EA_new/nsyb-G7f-rAch1h'\n",
    "atlas_path = data_path\n",
    "result_path = '../results/Ach-final-test'\n",
    "file_name = ['dff0_0-80_down2_C2','dff0_0-80_down2_C3']\n",
    "atlas_name = 'align_to_atlas/Transformed_atlas.tif'\n",
    "atlas_eroded_name = 'align_to_atlas/Transformed_atlas_eroded_r5.tif'\n",
    "num_fly = len(file_folder_list_1)\n",
    "atlas_z_range = range(13,38)\n",
    "num_channel = 2\n",
    "\n",
    "dff0_thresh = 1\n",
    "# cv fold\n",
    "cv_fold = 5\n",
    "# channel\n",
    "list_channel_selected = [0,1,2]\n",
    "num_channel_selected = len(list_channel_selected)\n",
    "# list_odor_choice\n",
    "list_odor_choice = [0]\n",
    "num_odor_choice = len(list_odor_choice)\n",
    "# thresh_pca_exp_var_2\n",
    "list_thresh_pca_exp_var_2 = np.arange(0,1,0.02)\n",
    "num_thresh = len(list_thresh_pca_exp_var_2)\n",
    "#######\n",
    "fly_selected = 1\n",
    "print(file_folder_list_1[fly_selected])\n",
    "\n",
    "## plot\n",
    "if_plot_figure = False\n",
    "if_save_figure = True\n",
    "\n",
    "# if_shuffle\n",
    "if_shuffle = [False,True]\n",
    "if_shuffle_flag = ['No_Shuffle','Shuffle']\n",
    "num_shuffle_choice = len(if_shuffle)\n",
    "\n",
    "## parameters for PCA\n",
    "pca_tp_range = range(1,15)\n",
    "## parameters for LDA and SVM\n",
    "lda_tp_selected = 3\n",
    "svm_tp_range = range(1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data done! size:\n",
      "(256, 256, 25, 40, 180, 2)\n",
      "load atlas done! size:\n",
      "(256, 256, 25)\n",
      "load atlas_eroded done! size:\n",
      "(256, 256, 25)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "file_folder_1 = file_folder_list_1[fly_selected]\n",
    "path_file_0 = data_path + '/' + file_folder_1 + '/' + file_name[0] + '.npy'\n",
    "path_file_1 = data_path + '/' + file_folder_1 + '/' + file_name[1] + '.npy'\n",
    "data_1 = np.load(path_file_0)\n",
    "data_1 = np.transpose(data_1,[3,4,2,1,0])\n",
    "data_2 = np.load(path_file_1)\n",
    "data_2 = np.transpose(data_2,[3,4,2,1,0])\n",
    "size_x = np.size(data_1,0)\n",
    "size_y = np.size(data_1,1)\n",
    "size_z = np.size(data_1,2)\n",
    "num_tp = np.size(data_1,3)\n",
    "num_trial = np.size(data_1,4)\n",
    "data = np.concatenate((data_1,data_2),axis = 4)\n",
    "del data_1,data_2\n",
    "data = data.reshape(size_x,size_y,size_z,num_tp,num_trial,num_channel,order = 'F')\n",
    "print('load data done! size:')\n",
    "print(np.shape(data))\n",
    "\n",
    "# load atlas\n",
    "file_folder_2 = file_folder_1[:-5]\n",
    "atlas= tf.imread(atlas_path + '/' + file_folder_2 + '/' + atlas_name)\n",
    "atlas = np.transpose(atlas,[1,2,0])\n",
    "atlas = atlas[:,:,atlas_z_range]\n",
    "print('load atlas done! size:')\n",
    "print(np.shape(atlas))\n",
    "atlas_eroded= tf.imread(atlas_path + '/' + file_folder_2 + '/' + atlas_eroded_name)\n",
    "atlas_eroded = np.transpose(atlas_eroded,[1,2,0])\n",
    "atlas_eroded = atlas_eroded[:,:,atlas_z_range]\n",
    "print('load atlas_eroded done! size:')\n",
    "print(np.shape(atlas_eroded))\n",
    "\n",
    "# regions\n",
    "list_regions = np.unique(atlas_eroded)\n",
    "list_regions = list_regions[list_regions>0]\n",
    "num_regions = len(br_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBPED_L\n",
      "MBVL_L\n",
      "MBML_L\n",
      "LH_L\n",
      "SLP_L\n",
      "SIP_L\n",
      "SMP_L\n",
      "CRE_L\n",
      "EB\n",
      "MBPED_L\n",
      "MBVL_L\n",
      "MBML_L\n",
      "LH_L\n",
      "SLP_L\n",
      "SIP_L\n",
      "SMP_L\n",
      "CRE_L\n",
      "EB\n",
      "MBPED_L\n",
      "MBVL_L\n",
      "MBML_L\n",
      "LH_L\n",
      "SLP_L\n",
      "SIP_L\n",
      "SMP_L\n",
      "CRE_L\n",
      "EB\n"
     ]
    }
   ],
   "source": [
    "list_list_num_dim = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,num_shuffle_choice))\n",
    "list_list_accuracy = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,cv_fold,num_shuffle_choice))\n",
    "list_list_f1_weighted = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,cv_fold,num_shuffle_choice))\n",
    "list_list_AUC_weighted = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,cv_fold,num_shuffle_choice))\n",
    "list_list_accuracy_svm = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,cv_fold,num_shuffle_choice))\n",
    "list_list_stim = np.zeros((num_channel_selected,num_odor_choice,num_regions,num_thresh,len(stim),num_shuffle_choice))\n",
    "\n",
    "result_each_fly_path = os.path.abspath(result_path + '/' + file_folder_list_2[fly_selected] + '/' + 'each_region_L-DEEPCAD-formal')\n",
    "folder = os.path.exists(result_each_fly_path)\n",
    "if not folder:\n",
    "    os.makedirs(result_each_fly_path)\n",
    "    \n",
    "for j,channel_selected in enumerate(list_channel_selected):\n",
    "    for k,odor_choice in enumerate(list_odor_choice):\n",
    "        for m,region_selected in enumerate(br_index):\n",
    "            if not region_selected in list_regions:\n",
    "                continue\n",
    "            print(br_name[m])\n",
    "            for p in range(num_shuffle_choice):\n",
    "                if if_shuffle[p]:\n",
    "                    stim_2 = stim.copy()\n",
    "                    random.shuffle(stim_2)\n",
    "                else:\n",
    "                    stim_2 = stim.copy()\n",
    "                result_each_fly_path_1 = result_each_fly_path + '/' + if_shuffle_flag[p] + '/' + 'C_' + \\\n",
    "                                         str(channel_selected) + '_odor_choice_'+ str(odor_choice)\n",
    "                folder = os.path.exists(result_each_fly_path_1)\n",
    "                if not folder:\n",
    "                    os.makedirs(result_each_fly_path_1)\n",
    "                [x_origin,explained_variance_ratio] = pca_each_brain_region(data,stim_2,\n",
    "                                                                            atlas_eroded,\n",
    "                                          region_selected,br_name[m],channel_selected,\n",
    "                                          odor_choice,dff0_thresh,pca_tp_range,\n",
    "                                          if_plot_figure,if_save_figure,result_each_fly_path_1)\n",
    "                # np.save(result_each_fly_path_1 + '/' + 'x_origin.npy',x_origin)\n",
    "                for n,thresh_pca_exp_var_2 in enumerate(list_thresh_pca_exp_var_2):\n",
    "                    [num_dim,list_accuracy,list_f1_weighted,list_AUC_weighted,list_accuracy_svm] = \\\n",
    "                        odor_classification_each_brain_region(x_origin,num_tp,num_trial,\n",
    "                                          stim_2,explained_variance_ratio,br_name[m],\n",
    "                                          odor_choice,thresh_pca_exp_var_2,lda_tp_selected,\n",
    "                                          svm_tp_range,cv_fold,\n",
    "                                          if_plot_figure,if_save_figure,\n",
    "                                          result_each_fly_path_1)\n",
    "\n",
    "                    list_list_num_dim[j,k,m,n,p] = num_dim\n",
    "                    list_list_accuracy[j,k,m,n,:,p] = np.array(list_accuracy)\n",
    "                    list_list_f1_weighted[j,k,m,n,:,p] = np.array(list_f1_weighted)\n",
    "                    list_list_AUC_weighted[j,k,m,n,:,p] = np.array(list_AUC_weighted)\n",
    "                    list_list_accuracy_svm[j,k,m,n,:,p] = np.array(list_accuracy_svm)\n",
    "                    list_list_stim[j,k,m,n,:,p] = np.array(stim_2)\n",
    "\n",
    "np.save(result_each_fly_path + '/' + 'list_regions_each_region' + '.npy',br_index)\n",
    "np.save(result_each_fly_path + '/' + 'list_num_dim' + '.npy',list_list_num_dim)\n",
    "np.save(result_each_fly_path + '/' + 'list_accuracy_each_region' + '.npy',list_list_accuracy)\n",
    "np.save(result_each_fly_path + '/' + 'list_f1_weighted_each_region' + '.npy',list_list_f1_weighted)\n",
    "np.save(result_each_fly_path + '/' + 'list_AUC_weighted_each_region' + '.npy',list_list_AUC_weighted)\n",
    "np.save(result_each_fly_path + '/' + 'list_accuracy_svm_each_region' + '.npy',list_list_accuracy_svm)\n",
    "np.save(result_each_fly_path + '/' + 'list_stim' + '.npy',list_list_stim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
